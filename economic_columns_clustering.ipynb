{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"문재인 정부 기간 경제 신문의 칼럼 담론 분석\"\n",
        "subtitle: \"1. Clustering analysis을 중심으로\"\n",
        "author: \"sorrychoe\"\n",
        "format: \n",
        "  html: \n",
        "    smooth-scroll: true\n",
        "editor: visual\n",
        "execute: \n",
        "  echo: true\n",
        "  eval: true\n",
        "---"
      ],
      "id": "7b3abe50"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import BigKindsParser as bkp\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "plt.rcParams[\"font.family\"] = \"Malgun Gothic\"\n",
        "plt.rcParams['figure.figsize'] = 10,10\n",
        "sns.set(font=\"Malgun Gothic\", rc={\"axes.unicode_minus\":False}, style='white')\n",
        "df = pd.read_excel('./econo_columns_20170510-20220509.xlsx', engine = \"openpyxl\")"
      ],
      "id": "4656c96f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 개요\n",
        "본 내용은 칼럼 데이터에 문서 군집 분석 진행한 보고서이다.\n",
        "\n",
        "분석 언어는 Python을 사용했으며, 가장 보편적인 군집 분석 방법인 K-Means Clusteringdmf 사용했다. \n",
        "알고리즘은 Scikit-Learn의 KMeans() 함수를 활용하여 분석을 진행했다.\n",
        "\n",
        "군집 분석에 앞서 EDA를 먼저 진행하였다.\n",
        "\n",
        "## EDA \n",
        "\n",
        "먼저 언론사 별 칼럼 보도 빈도를 확인하였다. 빈도 분석은 필자가 직접 제작한 라이브러리 'BigKindsParser'의 press_counter 함수를 활용했다.\n"
      ],
      "id": "d50983d8"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_key = bkp.press_counter(df)\n",
        "\n",
        "sns.barplot(data = df_key, x = '기사', y = '언론사')\n",
        "\n",
        "plt.figure(facecolor = 'white')\n",
        "plt.show()"
      ],
      "id": "eb2f7b0c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<!-- ## 이상치 확인\n"
      ],
      "id": "b2c9e454"
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-12T14:44:48.696625Z",
          "start_time": "2022-10-12T14:44:48.681024Z"
        }
      },
      "source": [
        "outlier = df[df['언론사'] == '아시아경제'] ##아시아 경제 기사 추가 크롤링 필요"
      ],
      "id": "8af044a0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#| ExecuteTime: {end_time: '2022-10-12T14:44:49.674876Z', start_time: '2022-10-12T14:44:49.653460Z'}\n",
        "#| collapsed: true\n",
        "outlier['일자'] #아시아경제 기사는 2021년부터 빅카인즈에 기사를 업로드 2017~2020년 기사는 별도 크롤링 필요\n",
        "``` -->\n",
        "\n",
        "## 키워드 빈도\n",
        "\n",
        "언론사 빈도 분석에 이어 단어 빈도 분석을 진행하였다.\n",
        "시각화는 워드클라우드로 진행하였으며, 분석 알고리즘은 BigKindsParser를 통해 진행했다."
      ],
      "id": "854752ad"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_keywords = df['키워드']\n",
        "keywords = bkp.keywords_list(df_keywords)\n",
        "news_key = bkp.keyword_parser(keywords)\n",
        "news_key = bkp.duplication_remover(news_key)\n",
        "key = bkp.word_counter(news_key)\n",
        "news_key = bkp.counter_to_DataFrame(key)\n",
        "\n",
        "wc = WordCloud(font_path = './NanumBarunGothic.ttf',\n",
        "    width = 500,\n",
        "    height = 500,\n",
        "    background_color='white').generate_from_frequencies(news_key.set_index('단어').to_dict()[\"빈도\"])\n",
        "\n",
        "\n",
        "plt.figure(figsize = (10, 10))\n",
        "plt.imshow(wc)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "id": "d75a8adf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 언론사 별 키워드 분석\n",
        "\n",
        "더 자세한 분석을 위해 언론사 별로 나눈 키워드 분석도 진행했다.\n",
        "\n",
        "### 언론사별 키워드 분석 --> 한경\n"
      ],
      "id": "8eb47d99"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bkp.press_keywords_wordcloud(df, '한국경제')"
      ],
      "id": "a1d9921f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 언론사별 키워드 분석 --> 매경\n"
      ],
      "id": "9609ceee"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bkp.press_keywords_wordcloud(df, '매일경제')"
      ],
      "id": "5f4abae6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 언론사별 키워드 분석 --> 서경\n"
      ],
      "id": "f06a7a0b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bkp.press_keywords_wordcloud(df, '서울경제')"
      ],
      "id": "cec7a44f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 언론사별 키워드 분석 --> 파이낸셜\n"
      ],
      "id": "ae7d5c13"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bkp.press_keywords_wordcloud(df, '파이낸셜뉴스')"
      ],
      "id": "17ff6532",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 언론사별 키워드 분석 --> 헤럴드\n"
      ],
      "id": "56a7dd87"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bkp.press_keywords_wordcloud(df, '헤럴드경제')"
      ],
      "id": "224383c3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## TF-IDF 분석\n",
        "\n",
        "언론사별 용어 빈도는 비슷하게 나온다는 점에서, 주류 단어가 아닌 언론사마다 특징적으로 사용한 단어를 추출하기 위해 상대 빈도 분석을 진행하였다.\n",
        "\n",
        "상대 빈도 분석 방법은 tf-idf으로 진행하였다.\n"
      ],
      "id": "25b2a6a4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer "
      ],
      "id": "fae8a4ad",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 언론사별 상대 빈도 분석 --> 한경\n"
      ],
      "id": "8124bac0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "han_words = df[df['언론사'] == '한국경제']\n",
        "han_words = han_words['키워드']\n",
        "\n",
        "tfidf = TfidfVectorizer()\n",
        "tdm = tfidf.fit_transform(han_words)\n",
        "\n",
        "word_count1 = pd.DataFrame({\n",
        "    '단어': tfidf.get_feature_names(),\n",
        "    '빈도': tdm.sum(axis=0).flat\n",
        "}).sort_values('빈도', ascending = False).reset_index(drop = True)\n",
        "\n",
        "wc = WordCloud(font_path = './NanumBarunGothic.ttf',\n",
        "    width = 500,\n",
        "    height = 500,\n",
        "    background_color='white').generate_from_frequencies(word_count1.set_index('단어').to_dict()[\"빈도\"])\n",
        "\n",
        "\n",
        "plt.figure(figsize = (10, 10))\n",
        "plt.imshow(wc)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "id": "4bed2ab2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 언론사별 상대 빈도 분석 --> 매경\n"
      ],
      "id": "ad84e150"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mail_words = df[df['언론사'] == '매일경제']\n",
        "mail_words = mail_words['키워드']\n",
        "\n",
        "tfidf = TfidfVectorizer()\n",
        "tdm = tfidf.fit_transform(mail_words)\n",
        "\n",
        "word_count2 = pd.DataFrame({\n",
        "    '단어': tfidf.get_feature_names(),\n",
        "    '빈도': tdm.sum(axis=0).flat\n",
        "}).sort_values('빈도', ascending = False).reset_index(drop = True)\n",
        "\n",
        "wc = WordCloud(font_path = './NanumBarunGothic.ttf',\n",
        "    width = 500,\n",
        "    height = 500,\n",
        "    background_color='white').generate_from_frequencies(word_count2.set_index('단어').to_dict()[\"빈도\"])\n",
        "\n",
        "plt.figure(figsize = (10, 10))\n",
        "plt.imshow(wc)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "id": "640e0c4a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 언론사별 상대 빈도 분석 --> 서경\n"
      ],
      "id": "6a0122ac"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "seo_words = df[df['언론사'] == '서울경제']\n",
        "seo_words = seo_words['키워드']\n",
        "\n",
        "tfidf = TfidfVectorizer()\n",
        "tdm = tfidf.fit_transform(seo_words)\n",
        "\n",
        "word_count3 = pd.DataFrame({\n",
        "    '단어': tfidf.get_feature_names(),\n",
        "    '빈도': tdm.sum(axis=0).flat\n",
        "}).sort_values('빈도', ascending = False).reset_index(drop = True)\n",
        "\n",
        "wc = WordCloud(font_path = './NanumBarunGothic.ttf',\n",
        "    width = 500,\n",
        "    height = 500,\n",
        "    background_color='white').generate_from_frequencies(word_count3.set_index('단어').to_dict()[\"빈도\"])\n",
        "\n",
        "plt.figure(figsize = (10, 10))\n",
        "plt.imshow(wc)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "id": "40f0b3ec",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 언론사별 상대 빈도 분석 --> 파이낸셜\n"
      ],
      "id": "13f56ad9"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fin_words = df[df['언론사'] == '파이낸셜뉴스']\n",
        "fin_words = fin_words['키워드']\n",
        "\n",
        "tfidf = TfidfVectorizer()\n",
        "tdm = tfidf.fit_transform(fin_words)\n",
        "\n",
        "word_count4 = pd.DataFrame({\n",
        "    '단어': tfidf.get_feature_names(),\n",
        "    '빈도': tdm.sum(axis=0).flat\n",
        "}).sort_values('빈도', ascending = False).reset_index(drop = True)\n",
        "\n",
        "wc = WordCloud(font_path = './NanumBarunGothic.ttf',\n",
        "    width = 500,\n",
        "    height = 500,\n",
        "    background_color='white').generate_from_frequencies(word_count4.set_index('단어').to_dict()[\"빈도\"])\n",
        "\n",
        "plt.figure(figsize = (10, 10))\n",
        "plt.imshow(wc)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "id": "8790a8cb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 언론사별 상대 빈도 분석 --> 헤럴드\n"
      ],
      "id": "fa0f5e09"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "hero_words = df[df['언론사'] == '헤럴드경제']\n",
        "hero_words = hero_words['키워드']\n",
        "\n",
        "tfidf = TfidfVectorizer()\n",
        "tdm = tfidf.fit_transform(hero_words)\n",
        "\n",
        "word_count5 = pd.DataFrame({\n",
        "    '단어': tfidf.get_feature_names(),\n",
        "    '빈도': tdm.sum(axis=0).flat\n",
        "}).sort_values('빈도', ascending = False).reset_index(drop = True)\n",
        "\n",
        "wc = WordCloud(font_path = './NanumBarunGothic.ttf',\n",
        "    width = 500,\n",
        "    height = 500,\n",
        "    background_color='white').generate_from_frequencies(word_count5.set_index('단어').to_dict()[\"빈도\"])\n",
        "\n",
        "plt.figure(figsize = (10, 10))\n",
        "plt.imshow(wc)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "id": "96fed79a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 상대 빈도 별 순위 시각화\n",
        "\n",
        "각 언론사 별 상대 빈도 순위를 비교한 값은 다음과 같다.\n"
      ],
      "id": "b0ebe67b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "words_df1 = pd.concat([word_count1, word_count2], join='outer', axis=1)\n",
        "words_df1.columns = ['단어(한경)', '빈도(한경)', '단어(매경)', '빈도(매경)']\n",
        "words_df2 = pd.concat([word_count3, word_count4, word_count5], join='outer', axis=1)\n",
        "words_df2.columns = ['단어(서경)', '빈도(서경)','단어(파이낸셜)', '빈도(파이낸셜)','단어(헤럴드)', '빈도(헤럴드)']\n",
        "\n",
        "words_df = pd.concat([words_df1, words_df2], join = 'outer', axis = 1)\n",
        "\n",
        "words_df.head(20)"
      ],
      "id": "82d65fd0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dimension Reduction\n",
        "\n",
        "본격적인 군집 분석에 앞서, 데이터의 분포를 확인하고자 차원 축소를 진행하였다. \n",
        "\n",
        "차원 축소 진행을 위해 먼저 데이터 벡터화를 진행하였다.\n",
        "\n",
        "다만, 모든 데이터를 전부 넣을 경우, 컴퓨터가 연산량을 이기지 못하고 다운되는 경우가 재현되어,\n",
        "데이터는 2020년 이후의 데이터로만 분석을 진행하였다. \n",
        "\n",
        "전체 데이터에 대한 분석은 2편의 토픽 모델링에서 진행하였다.\n"
      ],
      "id": "327c17b6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def targeting(x):\n",
        "    if x == '한국경제':\n",
        "        return 0\n",
        "    elif x == '매일경제':\n",
        "        return 1\n",
        "    elif x == '서울경제':\n",
        "        return 2\n",
        "    elif x == '파이낸셜뉴스':\n",
        "        return 3\n",
        "    elif x == '헤럴드경제':\n",
        "        return 4\n",
        "    elif x == '아시아경제':\n",
        "        return 5\n",
        "    \n",
        "df['target'] = df['언론사'].apply(lambda x : targeting(x))\n",
        "\n",
        "df20 = df[df['일자'] >= 20200100]\n",
        "df10 = df[df['일자'] < 20200100]\n",
        "\n",
        "text20 = df20['키워드']\n",
        "text20_df = df20[['언론사', '제목']]"
      ],
      "id": "116d9f92",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "가장 먼저 차원 축소 방법론인 PCA(Principle Component Analysis)를 사용하였다. \n",
        "해당 방법을 통해 데이터를 2차원으로 축소하였다.\n"
      ],
      "id": "d2e3035a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('vect', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "])        \n",
        "vec = pipeline.fit_transform(text20).toarray()\n",
        "\n",
        "pca_df = PCA(n_components=2).fit_transform(vec)\n",
        "\n",
        "pca_df = pd.DataFrame(pca_df, columns = ['component 0', 'component 1'])"
      ],
      "id": "46bb221e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "시각화 결과는 다음과 같다.\n"
      ],
      "id": "440d8521"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pca_df['target'] = df['target']\n",
        "\n",
        "pca_0 = pca_df[pca_df['target'] == 0]\n",
        "pca_1 = pca_df[pca_df['target'] == 1]\n",
        "pca_2 = pca_df[pca_df['target'] == 2]\n",
        "pca_3 = pca_df[pca_df['target'] == 3]\n",
        "pca_4 = pca_df[pca_df['target'] == 4]\n",
        "pca_5 = pca_df[pca_df['target'] == 5]\n",
        "\n",
        "plt.scatter(pca_0['component 0'], pca_0['component 1'], color = 'blue', label = '한국경제')\n",
        "plt.scatter(pca_1['component 0'], pca_1['component 1'], color = 'orange', label = '매일경제')\n",
        "plt.scatter(pca_2['component 0'], pca_2['component 1'], color = 'green', label = '서울경제')\n",
        "plt.scatter(pca_3['component 0'], pca_3['component 1'], color = 'yellow', label = '파이낸셜')\n",
        "plt.scatter(pca_4['component 0'], pca_4['component 1'], color = 'pink', label = '헤럴드')\n",
        "plt.scatter(pca_5['component 0'], pca_5['component 1'], color = 'purple', label = '아시아경제')\n",
        "\n",
        "plt.xlabel('component 0')\n",
        "plt.ylabel('component 1')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "id": "ea2503ce",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "추가로 흝어진 정도를 파악하기 위해 T-SNE 방법을 사용했다.\n"
      ],
      "id": "f0e8f955"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "tsne = TSNE(n_components=2, learning_rate=400).fit_transform(vec)\n",
        "\n",
        "tsne_df = pd.DataFrame(tsne, columns = ['component 0', 'component 1'])"
      ],
      "id": "a185a592",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "시각화 결과는 다음과 같다.\n"
      ],
      "id": "a50ecacb"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "tsne_df['target'] = df['target']\n",
        "\n",
        "tsne_0 = tsne_df[tsne_df['target'] == 0]\n",
        "tsne_1 = tsne_df[tsne_df['target'] == 1]\n",
        "tsne_2 = tsne_df[tsne_df['target'] == 2]\n",
        "tsne_3 = tsne_df[tsne_df['target'] == 3]\n",
        "tsne_4 = tsne_df[tsne_df['target'] == 4]\n",
        "tsne_5 = tsne_df[tsne_df['target'] == 5]\n",
        "\n",
        "\n",
        "plt.scatter(tsne_0['component 0'], tsne_0['component 1'], color = 'blue', label = '한국경제')\n",
        "plt.scatter(tsne_1['component 0'], tsne_1['component 1'], color = 'orange', label = '매일경제')\n",
        "plt.scatter(tsne_2['component 0'], tsne_2['component 1'], color = 'green', label = '서울경제')\n",
        "plt.scatter(tsne_3['component 0'], tsne_3['component 1'], color = 'yellow', label = '파이낸셜')\n",
        "plt.scatter(tsne_4['component 0'], tsne_4['component 1'], color = 'pink', label = '헤럴드')\n",
        "plt.scatter(tsne_5['component 0'], tsne_5['component 1'], color = 'purple', label = '아시아경제')\n",
        "\n",
        "plt.xlabel('component 0')\n",
        "plt.ylabel('component 1')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "id": "a90f442b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## K-Means Clustering\n",
        "\n",
        "본격적으로 군집 분석에 들어가기 앞서, K-Means는 최적 군집 갯수를 정해줘야 한다.\n",
        "\n",
        "최적 군집 갯수 추론을 위해 Elbow Method를 사용하였다.\n"
      ],
      "id": "21e1d190"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from yellowbrick.cluster import KElbowVisualizer\n",
        "\n",
        "vzr = KElbowVisualizer(KMeans(), k=(2, 20))\n",
        "vzr.fit(pca_df)\n",
        "vzr.poof()"
      ],
      "id": "04b233cb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "분석 결과, 최적 토픽 갯수는 5개로 나타났다.\n",
        "\n",
        "해당 5개의 군집 분석 결과를 확인하기 위해 Silhouette Score 분석을 진행하였다.\n",
        "분석 최적화를 위해 정규화도 진행하였다.\n"
      ],
      "id": "f3c8091c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.preprocessing import Normalizer\n",
        "\n",
        "nor = Normalizer()\n",
        "vec_nor = nor.fit_transform(vec)"
      ],
      "id": "f27a68ca",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from yellowbrick.cluster import SilhouetteVisualizer\n",
        "\n",
        "kmeans= KMeans(n_clusters=5, max_iter=1000, random_state=0) #최적 Topic 개수 5개를 기점으로 진행\n",
        "visualizer = SilhouetteVisualizer(kmeans, colors='yellowbrick')"
      ],
      "id": "2ce180f1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "visualizer.fit(vec_nor)\n",
        "visualizer.show()"
      ],
      "id": "06aaabbc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "생각보다 실루엣 계수가 많이 낮게 나타났다.\n",
        "\n",
        "이러한 결과가 K-means 분석 모델의 결과가 안좋은 것인지, 텍스트 데이터 분석 방법론으로서 k-Means의 한계인 것인치는 확인이 필요해보인다.\n",
        "\n",
        "K-Means 군집 별 기사 갯수는 다음과 같다."
      ],
      "id": "ae4f36df"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "kmeans.fit(vec_nor)\n",
        "\n",
        "labels = kmeans.labels_\n",
        "\n",
        "text_df['군집'] = labels\n",
        "\n",
        "text_df.groupby('군집').size()"
      ],
      "id": "24dbce05",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "또한 이후 개별적으로 분석해낸 토픽의 양상은 다음과 같다.\n",
        "\n",
        "0번 토픽 = 부동산 관련 칼럼\n",
        "1번 토픽 = 코로나 관련 칼럼\n",
        "2번 토픽 = 북한 관련 칼럼\n",
        "3번 토픽 = 경제 정책 관련 칼럼\n",
        "4번 토픽 = 정치 이슈 관련 칼럼\n",
        "\n",
        "해당 결과를 토대로 PCA와 T-SNE를 진행한 결과는 다음과 같다.\n",
        "\n",
        "### PCA with K-means\n"
      ],
      "id": "d0b33bc8"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pca_df['cluster'] = labels\n",
        "\n",
        "pca_clu_0 = pca_df[pca_df['cluster'] == 0]\n",
        "pca_clu_1 = pca_df[pca_df['cluster'] == 1]\n",
        "pca_clu_2 = pca_df[pca_df['cluster'] == 2]\n",
        "pca_clu_3 = pca_df[pca_df['cluster'] == 3]\n",
        "pca_clu_4 = pca_df[pca_df['cluster'] == 4]\n",
        "\n",
        "plt.scatter(pca_clu_0['component 0'], pca_clu_0['component 1'], color = 'blue', label = '부동산')\n",
        "plt.scatter(pca_clu_1['component 0'], pca_clu_1['component 1'], color = 'orange', label = '코로나')\n",
        "plt.scatter(pca_clu_2['component 0'], pca_clu_2['component 1'], color = 'green', label = '북한')\n",
        "plt.scatter(pca_clu_3['component 0'], pca_clu_3['component 1'], color = 'purple', label = '경제 정책')\n",
        "plt.scatter(pca_clu_4['component 0'], pca_clu_4['component 1'], color = 'red', label = '정치')\n",
        "\n",
        "plt.xlabel('component 0')\n",
        "plt.ylabel('component 1')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "id": "5db50de2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### T-SNE with K-means\n"
      ],
      "id": "b68f18b8"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "tsne_df['cluster'] = labels\n",
        "\n",
        "tsne_clu0 = tsne_df[tsne_df['cluster'] == 0]\n",
        "tsne_clu1 = tsne_df[tsne_df['cluster'] == 1]\n",
        "tsne_clu2 = tsne_df[tsne_df['cluster'] == 2]\n",
        "tsne_clu3 = tsne_df[tsne_df['cluster'] == 3]\n",
        "tsne_clu4 = tsne_df[tsne_df['cluster'] == 4]\n",
        "\n",
        "# target 별 시각화\n",
        "plt.scatter(tsne_clu0['component 0'], tsne_clu0['component 1'], color = 'blue', label = '부동산')\n",
        "plt.scatter(tsne_clu1['component 0'], tsne_clu1['component 1'], color = 'orange', label = '코로나')\n",
        "plt.scatter(tsne_clu2['component 0'], tsne_clu2['component 1'], color = 'green', label = '북한')\n",
        "plt.scatter(tsne_clu3['component 0'], tsne_clu3['component 1'], color = 'purple', label = '경제 정책')\n",
        "plt.scatter(tsne_clu4['component 0'], tsne_clu4['component 1'], color = 'red', label = '정치')\n",
        "\n",
        "plt.xlabel('component 0')\n",
        "plt.ylabel('component 1')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "id": "f4374193",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}